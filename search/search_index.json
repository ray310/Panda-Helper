{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Panda-Helper","text":"<p>Quickly and easily inspect data so you can move on to more in-depth analysis.</p> <p>Panda-Helper is a simple, open-source, Python data-profiling tool for Pandas\u2019 DataFrames and Series that allows you to assess data quality and usefulness with minimal effort.</p> <ul> <li> <p> Install Panda-Helper</p> <p>Install <code>pandahelper</code> with <code>pip</code> or <code>anaconda</code> and get up and running in minutes</p> </li> <li> <p> API Reference</p> <p>Detailed description of the Panda-Helper API</p> </li> <li> <p> Tutorial</p> <p>Panda-Helper Tutorial</p> </li> <li> <p> Source Code</p> <p>Review, clone, or fork the source code</p> </li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#pandahelper.profiles","title":"pandahelper.profiles","text":"<p>Panda-Helper data profiles.</p>"},{"location":"api/#pandahelper.profiles.DataFrameProfile","title":"DataFrameProfile","text":"<pre><code>DataFrameProfile(df, *, name='', fmt='simple')\n</code></pre> <p>Pandas DataFrame data profile.</p> <p>Prepare data profile of Pandas DataFrame that can be displayed or saved.</p> <p>Attributes:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name of DataFrame profile if provided. Default value is \"\".</p> </li> <li> <code>shape</code>               (<code>tuple</code>)           \u2013            <p>Dataframe shape.</p> </li> <li> <code>dtypes</code>               (<code>pandas.Series</code>)           \u2013            <p>Data types of DataFrame index and Series in DataFrame.</p> </li> <li> <code>memory_usage</code>               (<code>pandas.Series</code>)           \u2013            <p>Memory usage (MB) of index and Series in DataFrame.</p> </li> <li> <code>num_duplicates</code>               (<code>int</code>)           \u2013            <p>Number of duplicated rows.</p> </li> <li> <code>nulls_per_row</code>               (<code>pandas.Series</code>)           \u2013            <p>Count of null values per row.</p> </li> <li> <code>null_stats</code>               (<code>list</code>)           \u2013            <p>Distribution statistics on nulls per row.</p> </li> <li> <code>time_diffs</code>               (<code>pandas.Series</code>)           \u2013            <p>Time diffs (gaps) if DataFrame has a DateTimeIndex.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>pandas.DataFrame</code>)           \u2013            <p>DataFrame to profile.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>optional): Name to assign to profile.</p> </li> <li> <code>fmt</code>               (<code>str</code>, default:                   <code>'simple'</code> )           \u2013            <p>optional): Printed table format. See https://github.com/astanin/python-tabulate for options.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If input is not a Pandas DataFrame.</p> </li> </ul>"},{"location":"api/#pandahelper.profiles.DataFrameProfile.save","title":"save","text":"<pre><code>save(path)\n</code></pre> <p>Save profile to provided path.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>Where to save profile.</p> </li> </ul>"},{"location":"api/#pandahelper.profiles.SeriesProfile","title":"SeriesProfile","text":"<pre><code>SeriesProfile(series, *, fmt='simple', freq_most_least=(10, 5), time_index=False)\n</code></pre> <p>Pandas Series data profile.</p> <p>Prepare data profile of Pandas Series that can be displayed or saved.</p> <p>Attributes:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name of Series.</p> </li> <li> <code>dtype</code>               (<code>numpy.dtype or Pandas dtype</code>)           \u2013            <p>Data types of Series within DataFrame.</p> </li> <li> <code>count</code>               (<code>int</code>)           \u2013            <p>Count of non-null values.</p> </li> <li> <code>num_unique</code>               (<code>int</code>)           \u2013            <p>Number of unique values.</p> </li> <li> <code>num_nulls</code>               (<code>int</code>)           \u2013            <p>Number of null values.</p> </li> <li> <code>frequency</code>               (<code>pandas.DataFrame</code>)           \u2013            <p>Frequency table with counts and percentage.</p> </li> <li> <code>stats</code>               (<code>dict</code>)           \u2013            <p>Distribution statistics for Series.</p> </li> <li> <code>time_diffs</code>               (<code>pandas.Series</code>)           \u2013            <p>Time diffs (gaps) if series is of type <code>datetime64</code>. Alternately, can be time diffs in a Series with a DateTimeIndex if the <code>time_index</code> parameter was set to <code>True</code> when creating Series Profile.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>series</code>               (<code>pandas.Series</code>)           \u2013            <p>Pandas Series to profile.</p> </li> <li> <code>fmt</code>               (<code>str</code>, default:                   <code>'simple'</code> )           \u2013            <p>optional): Printed table format. See: https://github.com/astanin/python-tabulate for options.</p> </li> <li> <code>freq_most_least</code>               (<code>tuple</code>, default:                   <code>(10, 5)</code> )           \u2013            <p>optional): Tuple (x, y) of the x most common and y least common values to display in frequency table.</p> </li> <li> <code>time_index</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>optional): Whether to use the index for calculating time diffs for a <code>datetime64</code>-related Pandas Series. Not relevant for non-time related Series.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If input is not a Pandas Series.</p> </li> </ul>"},{"location":"api/#pandahelper.profiles.SeriesProfile.save","title":"save","text":"<pre><code>save(path)\n</code></pre> <p>Save profile to provided path.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>Where to save profile.</p> </li> </ul>"},{"location":"api/#pandahelper.stats","title":"pandahelper.stats","text":"<p>Panda-Helper statistics functions.</p>"},{"location":"api/#pandahelper.stats.distribution_stats","title":"distribution_stats","text":"<pre><code>distribution_stats(series)\n</code></pre> <p>Return single-column Pandas DataFrame of distribution statistics.</p> <p>Parameters:</p> <ul> <li> <code>series</code>               (<code>pandas.Series</code>)           \u2013            <p>Pandas Series used to calculate distribution statistics. Distribution statistics will depend on series dtype. Supported dtypes are:</p> <ul> <li>int64</li> <li>float64</li> <li>bool</li> <li>complex128</li> <li>datetime64</li> <li>timedelta64</li> <li>period[] <li>interval</li> <p>Returns:</p> <ul> <li> <code>pandas.DataFrame</code>           \u2013            <p>pd.DataFrame: Single-column of calculated values with statistics as index.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If input is not a numeric-like pd.Series.</p> </li> </ul> <p>Examples:</p> <p>Distribution stats for Pandas Series of type <code>float64</code>:</p> <pre><code>&gt;&gt;&gt; from random import seed, gauss, expovariate\n&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; seed(314)\n&gt;&gt;&gt; series = pd.Series([gauss(mu=30, sigma=20) for x in range(200)])\n&gt;&gt;&gt; ph.distribution_stats(series)\n                               Statistic Value\n    count                           200.000000\n    min                             -23.643007\n    1%                              -11.918955\n    5%                                2.833604\n    25%                              17.553793\n    50%                              31.420759\n    75%                              42.074998\n    95%                              60.305435\n    99%                              72.028633\n    max                              81.547828\n    mean                             30.580535\n    standard deviation               18.277706\n    median                           31.420759\n    median absolute deviation        12.216607\n    skew                             -0.020083\n</code></pre> <p>Distribution stats for Pandas Series of type <code>datetime64</code>:</p> <pre><code>&gt;&gt;&gt; start = pd.Timestamp(2000, 1, 1)\n&gt;&gt;&gt; tds = [pd.Timedelta(hours=int(expovariate(lambd=.003))) for x in range(200)]\n&gt;&gt;&gt; times = [start + td for td in tds]\n&gt;&gt;&gt; series = pd.Series(times)\n&gt;&gt;&gt; ph.distribution_stats(series)\n                               Statistic Value\ncount                                      200\nmin                        2000-01-01 00:00:00\n1%                         2000-01-01 01:59:24\n5%                         2000-01-01 09:00:00\n25%                        2000-01-04 08:00:00\n50%                        2000-01-08 04:30:00\n75%                        2000-01-16 21:00:00\n95%                        2000-02-08 01:36:00\n99%                        2000-02-22 10:20:24\nmax                        2000-04-01 17:00:00\nmean                       2000-01-12 14:24:18\nstandard deviation  12 days 16:47:15.284423042\nmedian                     2000-01-08 04:30:00\n</code></pre> <p></p>"},{"location":"api/#pandahelper.stats.frequency_table","title":"frequency_table","text":"<pre><code>frequency_table(series)\n</code></pre> <p>Return value counts and relative frequency.</p> <p>Parameters:</p> <ul> <li> <code>series</code>               (<code>pandas.Series</code>)           \u2013            <p>Pandas Series used to calculate value counts and relative frequencies.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pandas.DataFrame</code>           \u2013            <p>Pandas DataFrame of value counts and percentages indexed by value.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If input is not a Pandas Series.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import random\n&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt;\n&gt;&gt;&gt; random.seed(314)\n&gt;&gt;&gt; cities = [\"Springfield\", \"Quahog\", \"Philadelphia\", \"Shelbyville\"]\n&gt;&gt;&gt; series = pd.Series(random.choices(cities, k = 200))\n&gt;&gt;&gt; ph.frequency_table(series)\n                  Count % of Total\n    Springfield      66     33.00%\n    Quahog           51     25.50%\n    Philadelphia     44     22.00%\n    Shelbyville      39     19.50%\n</code></pre>"},{"location":"api/#pandahelper.times","title":"pandahelper.times","text":"<p>Panda-Helper time-series functions.</p>"},{"location":"api/#pandahelper.times.category_gaps","title":"category_gaps","text":"<pre><code>category_gaps(series, threshold, max_cat=50)\n</code></pre> <p>Calculate sum of gaps for each category in time-indexed Series.</p> <p>Gaps are time differences in excess of expected time increment (threshold). Gap per category is relative to the minimum and maximum times in the Series. Intended for use with categorical-like Series.</p> <p>Parameters:</p> <ul> <li> <code>series</code>               (<code>pandas.Series</code>)           \u2013            <p>Categorical-like Series.</p> </li> <li> <code>threshold</code>               (<code>pandas.Timedelta</code>)           \u2013            <p>Threshold for the time difference to be considered a gap. For hourly data, threshold should be pd.Timedelta(hours=1).</p> </li> <li> <code>max_cat</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>Maximum number categories (unique values) before issuing warning and returning <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>[pandas.DataFrame, None]</code>           \u2013            <p>Key-value pairs with category name and associated gap. Will return None if number of categories exceeds <code>max_cat</code>.</p> </li> </ul> <p>Warns:</p> <ul> <li> <code>UserWarning</code>             \u2013            <p>If the number of categories (unique values) in the series exceeds <code>max_cat</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; start = pd.Timestamp(year=1999, month=1, day=1)\n&gt;&gt;&gt; a = pd.Series([\"A\"] * 30, index=pd.date_range(start, periods=30, freq=\"D\"))\n&gt;&gt;&gt; b = pd.Series([\"B\"] * 15, index=pd.date_range(start, periods=15, freq=\"2D\"))\n&gt;&gt;&gt; c = pd.Series([\"C\"] * 10, index=pd.date_range(start, periods=10, freq=\"D\"))\n&gt;&gt;&gt; ph.category_gaps(pd.concat([a, b, c]), threshold=pd.Timedelta(days=1))\n              Cumulative Gap\n    C        20 days\n    B        15 days\n    A         0 days\n</code></pre>"},{"location":"api/#pandahelper.times.id_gaps","title":"id_gaps","text":"<pre><code>id_gaps(series, threshold)\n</code></pre> <p>Identify time gaps above <code>threshold</code> in datetime64 Series or DatetimeIndex.</p> <p>Sorts input by time before calculating gaps.</p> <p>Parameters:</p> <ul> <li> <code>series</code>               (<code>pandas.Series or pandas.DatetimeIndex</code>)           \u2013            <p><code>datetime64</code> Series or DatetimeIndex.</p> </li> <li> <code>threshold</code>               (<code>pandas.Timedelta</code>)           \u2013            <p>Threshold to identify gaps (and not expected time differences).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pandas.DataFrame</code>           \u2013            <p>One-column Pandas DataFrame of gaps indexed by when gap was calculated.</p> </li> </ul> <p>Examples:</p> <p>Identify time gaps on Series of timestamps with a 2 and 4 hour gap after it has been randomized:</p> <pre><code>&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; start = pd.Timestamp(year=1999, month=1, day=1)\n&gt;&gt;&gt; rng = pd.date_range(start, periods=24, freq=\"1h\").delete([3, 4, 8, 9, 10])\n&gt;&gt;&gt; series = pd.Series(rng).sample(frac=1, random_state=3)  # randomize order\n</code></pre> <pre><code>&gt;&gt;&gt; ph.id_gaps(series, pd.Timedelta(hours=1))\n                              diffs\n1999-01-01 11:00:00 0 days 04:00:00\n1999-01-01 04:00:00 0 days 02:00:00\n</code></pre>"},{"location":"api/#pandahelper.times.id_gaps_index","title":"id_gaps_index","text":"<pre><code>id_gaps_index(df, threshold)\n</code></pre> <p>Identify time gaps above <code>threshold</code> in time-indexed Series or DataFrame.</p> <p>Sorts input by time index before calculating diffs.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>pandas.Series or pandas.DataFrame</code>)           \u2013            <p>Time-indexed Series or DataFrame.</p> </li> <li> <code>threshold</code>               (<code>pandas.Timedelta</code>)           \u2013            <p>Threshold to identify gaps (and not expected time differences).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pandas.DataFrame</code>           \u2013            <p>One-column Pandas DataFrame of gaps indexed by when gap was calculated.</p> </li> </ul> <p>Examples:</p> <p>Identify time gaps on an hourly, time-indexed Series with a 2 and 4 hour gap after it has been randomized:</p> <pre><code>&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; start = pd.Timestamp(year=1999, month=1, day=1)\n&gt;&gt;&gt; rng = pd.date_range(start, periods=24, freq=\"1h\").delete([3, 8, 9, 10])\n&gt;&gt;&gt; # index by time then randomize order\n&gt;&gt;&gt; df = pd.DataFrame(range(len(rng)), index=rng).sample(frac=1, random_state=3)\n</code></pre> <pre><code>&gt;&gt;&gt; ph.id_gaps_index(df, pd.Timedelta(hours=1))\n                              diffs\n1999-01-01 11:00:00 0 days 04:00:00\n1999-01-01 04:00:00 0 days 02:00:00\n</code></pre>"},{"location":"api/#pandahelper.times.time_diffs","title":"time_diffs","text":"<pre><code>time_diffs(series)\n</code></pre> <p>Calculate time difference between subsequent observations.</p> <p>Sorts input by time before calculating diffs.</p> <p>Parameters:</p> <ul> <li> <code>series</code>               (<code>pandas.Series or pandas.DatetimeIndex</code>)           \u2013            <p>Pandas Series or DatetimeIndex to calculate time diffs on.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pandas.Series(pandas.Timedelta)</code>           \u2013            <p>Series of diffs (gaps) indexed by the time the diff was calculated.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If input is not Series of type datetime64 or DatetimeIndex.</p> </li> </ul> <p>Examples:</p> <p>Calculate time differences between observations on Series of timestamps after it has been randomized:</p> <pre><code>&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; start = pd.Timestamp(year=1999, month=1, day=1)\n&gt;&gt;&gt; rng = pd.date_range(start, periods=10, freq=\"D\").delete([3, 4, 5, 8])\n&gt;&gt;&gt; series = pd.Series(rng).sample(frac=1, random_state=3)  # randomize order\n</code></pre> <pre><code>&gt;&gt;&gt; ph.time_diffs(series)\n1999-01-01      NaT\n1999-01-02   1 days\n1999-01-03   1 days\n1999-01-07   4 days\n1999-01-08   1 days\n1999-01-10   2 days\nName: diffs, dtype: timedelta64[ns]\n</code></pre>"},{"location":"api/#pandahelper.times.time_diffs_index","title":"time_diffs_index","text":"<pre><code>time_diffs_index(df)\n</code></pre> <p>Calculate time difference between subsequent time-indexed observations.</p> <p>Sorts input by time index before calculating diffs.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>pandas.Series or pandas.DataFrame</code>)           \u2013            <p>Pandas Series or DataFrame with DateTimeIndex to calculate time diffs on.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pandas.Series(pandas.Timedelta)</code>           \u2013            <p>Series of diffs (gaps) indexed by the time the diff was calculated.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If input does not have a DatetimeIndex.</p> </li> </ul> <p>Examples:</p> <p>Calculate time differences between observations on time-indexed DataFrame after it has been randomized:</p> <pre><code>&gt;&gt;&gt; import pandahelper as ph\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; start = pd.Timestamp(year=1999, month=1, day=1)\n&gt;&gt;&gt; rng = pd.date_range(start, periods=10, freq=\"D\").delete([3, 4, 5, 8])\n&gt;&gt;&gt; # index by time then randomize order\n&gt;&gt;&gt; df = pd.DataFrame(range(len(rng)), index=rng).sample(frac=1, random_state=3)\n</code></pre> <pre><code>&gt;&gt;&gt; ph.time_diffs_index(df)\n1999-01-01      NaT\n1999-01-02   1 days\n1999-01-03   1 days\n1999-01-07   4 days\n1999-01-08   1 days\n1999-01-10   2 days\nName: diffs, dtype: timedelta64[ns]\n</code></pre>"},{"location":"install/","title":"Installing Panda-Helper","text":""},{"location":"install/#installing-with-pip","title":"Installing with <code>pip</code>","text":"<pre><code>pip install pandahelper\n</code></pre>"},{"location":"install/#installing-with-conda","title":"Installing with <code>conda</code>","text":"<p>If you manage conda environments with a <code>.yaml</code> file you can add <code>pandahelper</code> to the pip section of the .yaml as show here: <pre><code>name: my_env\nchannels:\n    - defaults\ndependencies:\n    - python=&lt;version&gt;\n    - pandas\n    - pip\n    - pip:\n        - pandahelper\n</code></pre> Then rebuild or update your conda environment.</p>"},{"location":"tutorial/","title":"Panda Helper Tutorial","text":"<p>For our Panda-Helper tutorial, we are going to use a dataset that counts how many  bicycles have passed through bike counting sensors at various locations in New York  City over time. We are going to merge the dataset with some additional metadata for  the sensors. The datasets can be downloaded from:</p> <ul> <li>Bicycle Counts: https://data.cityofnewyork.us/Transportation/Bicycle-Counts/uczf-rk3c/about_data</li> <li>Metadata: https://data.cityofnewyork.us/Transportation/Bicycle-Counters/smn3-rzf9/about_data</li> </ul>"},{"location":"tutorial/#loading-data","title":"Loading Data","text":"<p>Download and save data locally. <pre><code>import pandas as pd\n\nmetadata = pd.read_csv(\"data/Bicycle_Counters.csv\")\nbike_counts = pd.read_csv(\n    \"data/Bicycle_Counts.csv\",\n    index_col=\"date\",\n    parse_dates=[\"date\"],\n    date_format=\"%m/%d/%Y %I:%M:%S %p\",\n)\nbike_counts = bike_counts.join(metadata.set_index(\"id\"), on=\"id\", how=\"left\")\n</code></pre></p>"},{"location":"tutorial/#dataframe-profile","title":"DataFrame Profile","text":"<p>The <code>DataFrameProfile</code> is used to get a quick overview of the contents of a Pandas  DataFrame. It is an object that can be later referenced or saved if desired. In a single view it provides:</p> <ul> <li>DataFrame shape.</li> <li>Memory usage.</li> <li>The number of duplicated rows (if any).</li> <li>The datatypes of the individual Series.</li> <li>Statistics nulls per row to provide a view on data completeness.</li> <li>Time Differences (Diffs or Gaps) if it is a time-indexed DataFrame.<ul> <li>In the below example we see that most observations occur at the same time as    another observation or 15 minutes after the previous observation. There are a few    gaps where more than 15 minutes has passed since the last observation.</li> </ul> </li> </ul> <p><pre><code>import pandahelper as ph\n\nph.DataFrameProfile(bike_counts)\n</code></pre> <pre><code>DataFrame-Level Info\n----------------------  -------------\nDF Shape                (5589249, 12)\nDuplicated Rows         0\nMemory Usage (MB)       1,926.950\n\nSeries Name    Data Type         Memory Usage (MB)\n-------------  --------------  -------------------\nIndex          datetime64[ns]               44.714\ncountid        int64                        44.714\nid             int64                        44.714\ncounts         int64                        44.714\nstatus         int64                        44.714\nname           object                      438.682\ndomain         object                      368.89\nlatitude       float64                      44.714\nlongitude      float64                      44.714\ninterval       int64                        44.714\ntimezone       object                      419.194\nsens           int64                        44.714\ncounter        object                      297.758\n\nSummary of Nulls Per Row\n--------------------------  ---------\nNumber of Columns           12\nmin                          0\n1%                           0\n5%                           0\n25%                          0\n50%                          0\n75%                          0\n95%                          1\n99%                          1\nmax                          1\nmean                         0.240237\nstandard deviation           0.427228\nmedian                       0\nmedian absolute deviation    0\nskew                         1.21604\n\nTime Diffs         Count  % of total\n---------------  -------  ------------\n0 days 00:00:00  5176050  92.61%\n0 days 00:15:00   413183  7.39%\n0 days 01:15:00       12  0.00%\n0 days 02:15:00        1  0.00%\n0 days 00:30:00        1  0.00%\n0 days 06:15:00        1  0.00%\n</code></pre></p>"},{"location":"tutorial/#series-profile-numeric","title":"Series Profile (Numeric)","text":"<p>The <code>SeriesProfile</code> is used to get a quick overview of the contents of a Pandas  Series. It is an object that can be later referenced or saved if desired. In a single view it provides:</p> <ul> <li>Series data type (dtype).</li> <li>The number of non-null values.</li> <li>The number of unique values.</li> <li>The number of null values.</li> <li>The counts of some of the most common and least common values in the series which   can be configured with the optional <code>freq_most_least</code> flag</li> <li>Distribution statistics for the Series based on the data type.</li> </ul> <p>Counts are the number of bike crossings at a bike sensor in a window of time. <pre><code>ph.SeriesProfile(bike_counts[\"counts\"])\n</code></pre></p> <pre><code>counts Info\n-------------  -------\nData Type      int64\nCount          5589249\nUnique Values  897\nNull Values    0\n\n  Value    Count  % of total\n-------  -------  ------------\n      0   860809  15.40%\n      1   373805  6.69%\n      2   279622  5.00%\n      3   217329  3.89%\n      4   177636  3.18%\n      5   150857  2.70%\n      6   131232  2.35%\n      7   117491  2.10%\n      8   106717  1.91%\n      9    98373  1.76%\n    824        1  0.00%\n   1092        1  0.00%\n    925        1  0.00%\n    894        1  0.00%\n   1081        1  0.00%\n\nStatistic                           Value\n-------------------------  --------------\ncount                         5.58925e+06\nmin                           0\n1%                            0\n5%                            0\n25%                           2\n50%                          13\n75%                          37\n95%                          93\n99%                         164\nmax                        1133\nmean                         26.4127\nstandard deviation           39.3405\nmedian                       13\nmedian absolute deviation    13\nskew                          5.17677\n</code></pre>"},{"location":"tutorial/#series-profile-object","title":"Series Profile (Object)","text":"<p>A <code>SeriesProfile</code> for an <code>object</code> Series will provide similar information as a numeric  Series but without distribution statistics. Here we use the optional <code>freq_most_least</code>  parameter to show a longer frequency table.</p> <p>Name is the designation of the bike sensor station. <pre><code>ph.SeriesProfile(bike_counts[\"name\"], freq_most_least=(20, 20))\n</code></pre> <pre><code>name Info\n-------------  -------\nData Type      object\nCount          5589249\nUnique Values  34\nNull Values    0\n\nValue                                                          Count  % of total\n-----------------------------------------------------------  -------  ------------\nManhattan Bridge Bike Comprehensive                           381148  6.82%\nManhattan Bridge Display Bike Counter                         381148  6.82%\nManhattan Bridge Ped Path                                     368665  6.60%\nEd Koch Queensboro Bridge Shared Path                         368504  6.59%\nWilliamsburg Bridge Bike Path                                 368433  6.59%\nBrooklyn Bridge Bike Path                                     366111  6.55%\nComprehensive Brooklyn Bridge Counter                         365948  6.55%\nStaten Island Ferry                                           287203  5.14%\nProspect Park West                                            266080  4.76%\nKent Ave btw North 8th St and North 9th St                    264522  4.73%\nPulaski Bridge                                                243868  4.36%\n1st Avenue - 26th St N - Interference testing                 218169  3.90%\nManhattan Bridge 2012 to 2019 Bike Counter                    202785  3.63%\n8th Ave at 50th St.                                           195920  3.51%\nManhattan Bridge 2013 to 2018 Bike Counter                    165505  2.96%\nColumbus Ave at 86th St.                                      162481  2.91%\nAmsterdam Ave at 86th St.                                     162369  2.91%\n2nd Avenue - 26th St S                                        136388  2.44%\nBrooklyn Bridge Bicycle Path (Roadway)                         95955  1.72%\nKent Ave btw South 6th St. and Broadway                        78478  1.40%\n111th St at 50th Ave                                           72567  1.30%\nFountain Ave                                                   63146  1.13%\nWillis Ave                                                     62148  1.11%\nWillis Ave Bikes                                               62148  1.11%\nWillis Ave Peds                                                62148  1.11%\nManhattan Bridge 2012 Test Bike Counter                        36179  0.65%\nManhattan Bridge Interference Calibration 2019 Bike Counter    27675  0.50%\nOcean Pkwy at Avenue J                                         27260  0.49%\nPelham Pkwy                                                    21452  0.38%\nBroadway at 50th St                                            20544  0.37%\nHigh Bridge                                                    16276  0.29%\nEmmons Ave                                                     16267  0.29%\nForsyth Plaza                                                  14998  0.27%\nConcrete Plant Park                                             6761  0.12%\n</code></pre></p>"},{"location":"tutorial/#time-series-functionality","title":"Time Series Functionality","text":""},{"location":"tutorial/#calculate-the-cumulative-gaps-in-time-series-data-by-category","title":"Calculate the cumulative gaps in time series data by category","text":"<p>In the above example we saw a notable difference in the number of observations per  bike counter station. We can use <code>category_gaps</code> to check for gaps in  time-indexed, categorical-like data. We use the <code>threshold</code> parameter to define the  maximum expected increment in the time-indexed data. Some of the bike stations report  data every 15 minutes and some report data every hour so we can use a threshold of one  hour.</p> <p><pre><code>ph.category_gaps(bike_counts[\"name\"], threshold=pd.Timedelta(hours=1))\n</code></pre> <pre><code>                                                       Cumulative Gap\nConcrete Plant Park                                4234 days 13:45:00\nForsyth Plaza                                      4148 days 16:15:00\nEmmons Ave                                         4135 days 12:30:00\nHigh Bridge                                        4135 days 10:15:00\nBroadway at 50th St                                4090 days 10:30:00\nPelham Pkwy                                        4081 days 12:15:00\nOcean Pkwy at Avenue J                             4021 days 00:15:00\nManhattan Bridge Interference Calibration 2019 ... 4016 days 15:00:00\nManhattan Bridge 2012 Test Bike Counter            3928 days 01:30:00\nWillis Ave Peds                                    3657 days 12:45:00\nWillis Ave Bikes                                   3657 days 12:45:00\nWillis Ave                                         3657 days 12:45:00\nFountain Ave                                       3647 days 01:45:00\n111th St at 50th Ave                               3548 days 21:45:00\nKent Ave btw South 6th St. and Broadway            3487 days 06:30:00\nBrooklyn Bridge Bicycle Path (Roadway)             3305 days 06:45:00\n2nd Avenue - 26th St S                             2884 days 02:30:00\nAmsterdam Ave at 86th St.                          2613 days 09:30:00\nColumbus Ave at 86th St.                           2612 days 06:00:00\nManhattan Bridge 2013 to 2018 Bike Counter         2580 days 19:15:00\n8th Ave at 50th St.                                2263 days 19:00:00\nManhattan Bridge 2012 to 2019 Bike Counter         2192 days 07:30:00\n1st Avenue - 26th St N - Interference testing      2032 days 00:00:00\nPulaski Bridge                                     1764 days 08:45:00\nKent Ave btw North 8th St and North 9th St         1549 days 04:30:00\nProspect Park West                                 1533 days 00:30:00\nStaten Island Ferry                                1312 days 22:15:00\nComprehensive Brooklyn Bridge Counter               492 days 13:45:00\nBrooklyn Bridge Bike Path                           490 days 21:45:00\nWilliamsburg Bridge Bike Path                       466 days 15:00:00\nEd Koch Queensboro Bridge Shared Path               465 days 22:45:00\nManhattan Bridge Ped Path                           464 days 07:15:00\nManhattan Bridge Bike Comprehensive                 333 days 14:45:00\nManhattan Bridge Display Bike Counter               333 days 14:45:00\n</code></pre></p>"},{"location":"tutorial/#identify-when-gaps-occur-in-time-series-data","title":"Identify when gaps occur in time series data","text":"<p>It looks like the 'Manhattan Bridge Bike Comprehensive' category has the smallest  amount of missing time. We can use <code>id_gaps_index</code> to identify when the gaps occur.  We see that the largest gap for this bike sensor is ~328 days long in 2013.</p> <p><pre><code>mbc = bike_counts[\"name\"][bike_counts[\"name\"] == \"Manhattan Bridge Bike Comprehensive\"]\nph.id_gaps_index(mbc, threshold=pd.Timedelta(hours=1))\n</code></pre> <pre><code>                                diffs\ndate  \n2013-12-03 00:00:00 328 days 00:15:00\n2023-09-27 02:15:00   2 days 02:30:00\n2024-01-21 02:15:00   1 days 02:30:00\n2023-07-03 02:15:00   1 days 02:30:00\n2023-07-01 02:15:00   1 days 02:30:00\n2013-12-03 11:00:00   0 days 06:15:00\n2012-10-12 15:00:00   0 days 02:15:00\n2021-03-14 03:00:00   0 days 01:15:00\n2023-03-12 03:00:00   0 days 01:15:00\n2022-03-13 03:00:00   0 days 01:15:00\n2019-03-10 03:00:00   0 days 01:15:00\n2020-03-08 03:00:00   0 days 01:15:00\n2018-03-11 03:00:00   0 days 01:15:00\n2017-03-12 03:00:00   0 days 01:15:00\n2016-03-13 03:00:00   0 days 01:15:00\n2015-03-08 03:00:00   0 days 01:15:00\n2014-11-04 05:00:00   0 days 01:15:00\n2014-03-09 03:00:00   0 days 01:15:00\n2024-03-10 03:00:00   0 days 01:15:00\n</code></pre></p>"}]}